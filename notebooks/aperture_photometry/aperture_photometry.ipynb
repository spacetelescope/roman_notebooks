{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aperture Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Kernel Information and Read-Only Status\n",
    "\n",
    "To run this notebook, please select the \"Roman Research Nexus\" kernel at the top right of your window.\n",
    "\n",
    "This notebook is read-only. You can run cells and make edits, but you must save changes to a different location. We recommend saving the notebook within your home directory, or to a new folder within your home (e.g. <span style=\"font-variant:small-caps;\">file > save notebook as > my-nbs/nb.ipynb</span>). Note that a directory must exist before you attempt to add a notebook to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook explains how to perform **forced aperture photometry** (also known as *forced photometry* or *aperture photometry*) on Roman WFI images. Aperture photometry is useful for measuring the integrated fluxes for a set of specified source positions and aperture sizes. This technique is often valuable for extracting fluxes of known sources when it is impractical to fit for their positions and light distributions, or when simplicity and speed are high priorities. For example, aperture photometry can be used for:\n",
    "\n",
    "- **Faint sources.** If a source is too faint, then it can be difficult to fit for the source centroid, light profile, and flux.\n",
    "- **Sources detected at other wavelengths.** If a source is detected in a given bandpass, and the source size is expected to be the same across wavelengths, then it can be useful to define one aperture and measure the source fluxes across multiple filters.\n",
    "- **Time-series evolution of sources.** If a source brightness is decreasing over time, then we can use earlier observations obtained when the source was bright to specify an aperture and extract the flux in a time series.\n",
    "\n",
    "Here, we cover a simple example using the `photutils` package to extract fluxes from a catalog of known sources.\n",
    "\n",
    "Please note that the WFI calibration is currently measured from ground test data, and changes are expected after launch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Data\n",
    "\n",
    "The cell below will check to ensure ancillary reference files for `stpsf` package are installed. If not, it will download the ancillary reference files and install them under your home directory (i.e., `${HOME}/refdata/`).\n",
    "\n",
    "### Local Run Settings\n",
    "\n",
    "If you want to run the notebook in your local machine, refer to the information in [local installation](../../markdown/local-run.md) instructions before proceeding with the notebook. The instructions provide inportant information about setting up your environment, installing dependnecies, and adding to your working directory scripts to help with the reference data installation.\n",
    "\n",
    "Depending on which (if any) reference data are missing, this cell may take several minutes to execute.\n",
    "\n",
    "### On the Roman Research Nexus\n",
    "\n",
    "If you are working on the Nexus, then the ancillary reference data are pre-installed and this cell will execute instantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data & Environment Setup ---\n",
    "# This cell configures reference data and environment variables.\n",
    "# On the Roman Research Nexus (RNN), everything is pre-configured and\n",
    "# this cell completes instantly.  For local or CI execution it will\n",
    "# download any missing reference data automatically.\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "REQUIRED_DATA = ['stpsf']\n",
    "\n",
    "# Load the setup module ---------------------------------------------------\n",
    "try:\n",
    "    import notebook_data_dependencies as ndd\n",
    "except ImportError:\n",
    "    # Walk up from the notebook directory to find shared/notebook_data_dependencies.py\n",
    "    _here = Path(os.getcwd())\n",
    "    for _parent in [_here] + list(_here.parents):\n",
    "        _candidate = _parent / 'shared' / 'notebook_data_dependencies.py'\n",
    "        if _candidate.exists():\n",
    "            import importlib.util\n",
    "            _spec = importlib.util.spec_from_file_location('notebook_data_dependencies', _candidate)\n",
    "            ndd = importlib.util.module_from_spec(_spec)\n",
    "            _spec.loader.exec_module(ndd)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            'Cannot find shared/notebook_data_dependencies.py in any parent directory.\\n'\n",
    "            'Make sure you are running from within the roman_notebooks repo.'\n",
    "        )\n",
    "\n",
    "# Download missing reference data (no-op when env vars are already set) ---\n",
    "result = ndd.install_files(packages=REQUIRED_DATA) if REQUIRED_DATA else {}\n",
    "ndd.setup_env(result)  # Sets data paths + CRDS env vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We are using standard libraries from the Numpy and Astropy stack.\n",
    "\n",
    "- *astropy*\n",
    "- *numpy*\n",
    "- *copy*\n",
    "- *matplotlib*\n",
    "- *photutils* is an Astropy-affiliated package for photometry\n",
    "- *roman_datamodels* opens and validates WFI data files\n",
    "- *asdf* opens WFI data files\n",
    "- *os* for checking if files exist\n",
    "- *s3fs* streams data from Simple Storage Service (S3) buckets on Amazon Web Services (AWS)\n",
    "- *stpsf* for retrieving the encircled energy profile of stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from astropy.stats import SigmaClip, sigma_clipped_stats\n",
    "import asdf\n",
    "import crds\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry, ApertureStats\n",
    "import roman_datamodels as rdm\n",
    "import s3fs\n",
    "import stpsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tutorial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Data\n",
    "\n",
    "In this tutorial, we use a Level 2 (L2; calibrated rate image) WFI data file that is the result of RomanCal processing of a Level 1 (L1; uncalibrated ramp cube) simulated file created with Roman I-Sim. If you have already worked through the tutorials \"Simulating WFI Imaging Data with Roman I-Sim\" and \"Calibrating WFI Exposures with RomanCal,\" then you may already have these files saved locally. If not, then these files are also stored in the Nexus S3 bucket and will be downloaded. For more information on how to access these data, see the [Data Discovery and Access](../data_discovery_and_access/data_discovery_and_access.ipynb) tutorial.\n",
    "\n",
    "As a reminder, the file we are using is a L2 file meaning that the data were processed to flag and/or correct for detector-level effects (e.g., saturation, classic non-linearity, etc.), and that the ramp was fitted into a count rate image in units of Data Numbers (DN) per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stream the files from the S3 bucket if they are not in local storage\n",
    "\n",
    "if os.path.exists('r0003201001001001004_0001_wfi01_f106_cal.asdf'):\n",
    "    f = rdm.open('r0003201001001001004_0001_wfi01_f106_cal.asdf')\n",
    "else:\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    asdf_dir_uri = 's3://stpubdata/roman/nexus/soc_simulations/tutorial_data/'\n",
    "    asdf_file_uri = asdf_dir_uri + 'r0003201001001001004_0001_wfi01_f106_cal.asdf'\n",
    "    f = rdm.open(fs.open(asdf_file_uri, 'rb'))\n",
    "\n",
    "image = f.data\n",
    "err = f.err\n",
    "dq = np.bool(f.dq)\n",
    "meta = f.meta\n",
    "wcs = f.meta.wcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Catalog\n",
    "\n",
    "We also need access to a source catalog that was used to simulate the WFI image. It contains stars and galaxies, which are labeled as \"PSF\" and \"SER\" under the column `type`. Source fluxes are available in all WFI filters (F062, F087, F106, F129, F146, F158, F184, and F213) and are sampled from a lognormal distribution. Note that fluxes are all given in *maggies*, which are defined as ${\\rm maggie} \\equiv 10^{-0.4 m_{AB}}$, for an AB apparent magnitude $m_{AB}$. \n",
    "\n",
    "For galaxies, morphological parameters like `n` (Sersic index), `half_light_radius`, `pa` (position angle), and `ba` (axis ratio) are also provided in the catalog. In this simulation, these are sampled according to fiducial (and likely unrealistic) distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stream the files from the S3 bucket if they are not in local storage\n",
    "\n",
    "if os.path.exists('full_catalog.ecsv'):\n",
    "    cat = Table.read('full_catalog.ecsv')\n",
    "else:\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    asdf_dir_uri = 's3://stpubdata/roman/nexus/soc_simulations/tutorial_data/'\n",
    "    asdf_file_uri = asdf_dir_uri + 'full_catalog.ecsv'\n",
    "    cat = Table.read(fs.open(asdf_file_uri, 'rb'), format='ascii.ecsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the first five rows and all columns of the catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert (RA, Dec) to (x, y) positions on the WFI01 detector. Note that several of these positions may be NaN (Not a Number) as they fall outside the bounding box of the WCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat, y_cat = wcs.invert(cat[\"ra\"].data, cat[\"dec\"].data)\n",
    "cat['x'] = x_cat\n",
    "cat['y'] = y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be helpful to quantify the number of sources there are before we try to visualize them! We first create a mask of sources that actually fall on the detector, and then divide the remaining sources into stars and galaxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mas with the sources falling on the detector\n",
    "mask = (np.isfinite(x_cat) & np.isfinite(y_cat))\n",
    "print(f\"Number of sources on detector: {sum(mask)}\")\n",
    "\n",
    "# Classify the sources in stars and galaxies\n",
    "stars = cat[mask & (cat[\"type\"] == \"PSF\")]\n",
    "galaxies = cat[mask & (cat[\"type\"] == \"SER\")]\n",
    "print(f\"Number of stars: {len(stars)}\\nNumber of galaxies: {len(galaxies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the distribution of source fluxes using a histogram. We will plot the flux from the input catalog in units of AB magnitudes. Recall that the input catalog is in units of maggies. Using the transformation from maggies to AB magnitudes given by the equation:\n",
    "\n",
    "$m_{\\mathrm{AB}} = -2.5 \\times \\log_{10}(f_{\\mathrm{maggies}})$\n",
    "\n",
    "we get the data in the right units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to AB magnitudes\n",
    "stars['abmag'] = -2.5 * np.log10(stars['F106'])\n",
    "galaxies['abmag'] = -2.5 * np.log10(galaxies['F106'])\n",
    "\n",
    "# Create an histogram to identify the number\n",
    "# of stars and galaxies with different AB magnitides.\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(stars['abmag'], bins=50, range=[16, 24], log=True, label='Stars')\n",
    "ax.hist(galaxies['abmag'], bins=50, range=[16, 24], log=True, label='Galaxies')\n",
    "\n",
    "ax.set_xlabel(r'$m_{\\mathrm{AB, F106}}$')\n",
    "ax.set_ylabel('Number of Sources')\n",
    "ax.xaxis.set_inverted(True)\n",
    "ax.legend()\n",
    "\n",
    "ax.grid(alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forced Aperture Photometry\n",
    "\n",
    "Forced aperture photometry uses predefined source positions to place apertures and measure the flux within them. We use the source catalog information provided above for this. If source positions are unavailable, you will need to perform source detection first to determine their locations (see [Additional Resources](#Additional-Resources)).\n",
    "\n",
    "### Correcting for Pixel Area\n",
    "\n",
    "First, we need to correct our data for geometric distortion, which causes pixels to have different areas projected on the sky. The WFI distortion is described by a 2-D polynomial, and the area of each pixel is given by the determinant of the Jacobian matrix of this polynomial. A reference file, called the Pixel Area Map (PAM), provides the area per pixel of each WFI detector normalized to the nominal pixel area. The nominal pixel area is the pixel area at the tangent point about which the distortion polynomial is defined.\n",
    "\n",
    "First, we can use the `crds` Python package to request the best pixel area map reference file that matches our observation. For this, CRDS needs to know the instrument name (WFI), detector name (WFI01), and the start time of the exposure. We can pull all of this information out of the metadata of the L2 file. Note that we need to specify the start time as a string, so we use `meta.exposure.start_time.isot` to convert the `astropy.time.Time` object in the metadata to an ISOT string (i.e., it has the format YYYY-MM-DDTHH:MM:SS.SSS). We set the argument `ignore_cache=True` below to force CRDS to update the files in our local cache. If this cell is re-run, we can set `ignore_cache=False` as we are confident we have pulled the latest information from the CRDS server. We also specify that the observatory is \"roman\" and that we want the \"area\" reference file type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crds_result = crds.getreferences({'ROMAN.META.INSTRUMENT.DETECTOR': meta.instrument.detector,\n",
    "                                  'ROMAN.META.INSTRUMENT.NAME': meta.instrument.name,\n",
    "                                  'ROMAN.META.EXPOSURE.START_TIME': meta.exposure.start_time.isot}, \n",
    "                                 observatory='roman', reftypes=['area'], ignore_cache=True)\n",
    "\n",
    "print(crds_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a dictionary is returned. The keys of the dictionary are the reference file types (e.g., \"area\"), and the values are the path to the correct file in your local CRDS cache. If the file is not in your cache, then the `crds.getreferences()` function will download the file to your local cache. At this time, CRDS does not support streaming reference files into memory from the CRDS server, but work is ongoing to adapt CRDS to cloud applications.\n",
    "\n",
    "Let's take a look at the pixel area map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam = rdm.open(crds_result['area'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "img = ax.imshow(pam.data, origin='lower')\n",
    "ax.set_xlabel('X science coordinate (pixels)')\n",
    "ax.set_ylabel('Y science coordinate (pixels)')\n",
    "ax.set_title(f'Pixel Area Map for {pam.meta.instrument.detector}')\n",
    "plt.colorbar(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's multiply the science data and the uncertainty array by the PAM to adjust for the relative sizes of the pixels on the sky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image *= pam.data\n",
    "err *= pam.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Apertures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will focus on the stars from this point on. From the catalogs, we now know the positions of every star. We can define a set aperture radii in units of pixels. In here we choose radii of 3 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = 3  # aperture radius in pixels\n",
    "\n",
    "star_positions = [(x, y) for y, x in zip(stars['y'].data, stars['x'].data)]\n",
    "star_apertures = CircularAperture(positions=star_positions, r=rad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's create annulus apertures with $r_{in} = 20$ pixels and $r_{out} = 25$ pixels to measure local sky background values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_bkg_apertures = CircularAnnulus(positions=star_positions, r_in=20, r_out=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Visualization\n",
    "\n",
    "Let's plot our apertures on a subsection of the image to visually confirm that we have placed our apertures correctly. There may be a few small, fuzzy galaxies in the image that are not marked. This is fine since we are focusing on stars. Similarly, there may be several small features, detector imperfections, that are also not marked. Those will be masked in the data quality array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "# show the simulated image\n",
    "ax.imshow(image, origin='lower', vmin=0, vmax=12, cmap='gray_r')\n",
    "\n",
    "# plot circles over bright galaxies and stars\n",
    "star_apertures.plot(color='cornflowerblue')\n",
    "star_bkg_apertures.plot(color='cornflowerblue', ls=':')\n",
    "\n",
    "# zoom in on 1/16th of the image\n",
    "ax.set_xlim(1024, 1536)\n",
    "ax.set_ylim(1024, 1536)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture Photometry with Photutils\n",
    "\n",
    "We can now perform aperture photometry on the selected sources. First we measure the photometry in a circular aperture on each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('id', 'xcentroid', 'ycentroid', 'sum', 'sum_err')\n",
    "star_phot = ApertureStats(image, star_apertures, error=err)\n",
    "phot_tab = star_phot.to_table(columns)\n",
    "phot_tab[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's do the same for the background annuli using the `ApertureStats` class. We will use the median of the pixels within the annulus as our estimate of the sky background **per pixel**. We will need to adjust this to the area of the star circular apertures (after accounting for the masked pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('id', 'xcentroid', 'ycentroid', 'median', 'std')\n",
    "sigclip = SigmaClip(sigma=3.0, maxiters=5)\n",
    "star_bkg = ApertureStats(image, star_bkg_apertures, sigma_clip=sigclip, mask=dq)\n",
    "star_bkg.to_table(columns)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next steps, we will need the nominal pixel area in steradians (sr) and the zeropoint in megaJanskys per steradian (MJy/sr), both of which can be retrieved from the L2 metadata. Note that the pre-launch zeropoint is based on the unit response of the throughput curve of the integrated optical system (i.e., including all of the mirror reflectivities, optical element transmission, and detector quantum efficiency). The zeropoint also includes a factor of the median measured gain of the detector. The pre-launch zeropoint uncertainty is based solely on the standard deviation of the measured gain. After launch, these values will be updated using on-orbit observations of spectrophotometric standard stars and the photometric touchstone fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zpt = meta.photometry.conversion_megajanskys\n",
    "pixel_area = meta.photometry.pixel_area\n",
    "\n",
    "print(f'Zeropoint = {zpt} (MJy/sr) / (DN/s)')\n",
    "print(f'Nominal pixel area = {pixel_area} sr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we subtract the sky background values from the source fluxes and propagate the uncertainty in the background into the total uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_bkgsub = star_phot.sum - (star_bkg.median * star_apertures.area)\n",
    "phot_tab['flux_jy'] = flux_bkgsub * zpt * 1e6 * pixel_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to correct our fluxes for the fraction of the starlight that falls outside of the aperture. The amount of light within the aperture as a function of the total light within a hypothetical infinite aperture is called the encircled energy and can be either measured from the image data using a series of apertures or can be determined from STPSF. In the future, a reference file in CRDS will also provide this information. For now, let's use STPSF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfi = stpsf.WFI()\n",
    "wfi.filter = meta.instrument.optical_element\n",
    "wfi.detector = f'SCA{meta.instrument.detector[-2:]}'\n",
    "wfi.detector_position = (2043.5, 2043.5)\n",
    "wfi_psf = wfi.calc_psf()\n",
    "ee_func = stpsf.measure_ee(wfi_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the encircled energy as a function of aperture radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpsf.display_ee(wfi_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these settings, our encircled energy measurement is an average for the whole detector, measured at the center of the detector, and for the default STPSF spectral energy distribution (SED), which is a 5700 K blackbody (similar to a G2V star). The variable `ee_func` above is a function that takes as its single argument the aperture radius in arcseconds and returns the percentage of the PSF contained within that aperture. The inverse of that encircled energy fraction is the correction factor that we must apply to our measurements. This is called the encircled energy correction or aperture correction. Let's calculate that now for a circular aperture with a 3-pixel radius and assuming a pixel scale of 0.11 arcseconds per pixel (i.e., radius = 0.33 arcseconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_correction = 1/ee_func(rad * 0.11)\n",
    "print(f'Encircled energy correction = {ee_correction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the aperture correction to our flux, and then convert the flux in Jy to maggies and AB magnitudes. For any source with a flux in maggies less than 0, we will assign a value of NaN for the AB magnitude. Recall that maggies are defined such that 1 maggie is equal to the reference flux for the AB magnitude system, which is 3,631 Jy. Thus, to convert our measurements from Jankys to maggies, we divide our fluxes by 3,631 Jy. We will also mask out any sources that have a flux of less than or equal to zero as those will not convert to magnitudes. Such sources exist where the background flux was statistically higher than the measured source flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_tab['flux_jy'] *= ee_correction\n",
    "phot_tab['flux_maggies'] = phot_tab['flux_jy'] / 3631\n",
    "\n",
    "# Mask out things with flux <= 0\n",
    "mask = phot_tab['flux_maggies'] <= 0\n",
    "phot_tab['flux_maggies'][mask] = np.nan\n",
    "phot_tab['flux_jy'][mask] = np.nan\n",
    "\n",
    "# Convert the flux to AB magnitudes\n",
    "phot_tab['abmag'] = -2.5 * np.log10(phot_tab['flux_maggies'])\n",
    "\n",
    "phot_tab[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our results by plotting the difference between the simulated catalog and measured AB magnitudes. The blue points show the photometry of the stars, while the orange line shows the median offset between the input catalog and the measurements. The labeled uncertainty on the median is the standard deviation of the distribution. We also include a black line at an offset of 0 AB magnitudes as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "# Compute the offset between the input catalogs (stars) and measured (phot_tab) AB magnitudes and plot them\n",
    "offset = stars['abmag'] - phot_tab['abmag']\n",
    "ax.scatter(stars['abmag'], offset, s=5, color='cornflowerblue', alpha=0.3)\n",
    "\n",
    "# Compute the median offset ignoring NaNs and plot the median and a reference line at 0\n",
    "_, med, std = sigma_clipped_stats(offset[~np.isnan(offset)], sigma=5, maxiters=2)\n",
    "ax.axhline(med, c='darkorange', label=fr'Median $\\Delta m = {med:.3f}$ AB mag, Std. $\\Delta m = {std:.3f}$ AB mag', zorder=1e4)\n",
    "ax.axhline(0, color='black', zorder=-100)\n",
    "\n",
    "# Restrict the axis limits for visibility. You may need to change these if you alter the input\n",
    "# data for this tutorial.\n",
    "ax.set_xlim(21, 16.5)\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel(r'$m_{\\mathrm{AB, input}}$')\n",
    "ax.set_ylabel(r'$m_{\\mathrm{AB, input}} - m_{\\mathrm{AB, measured}}$')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "# Overplot a reference grid\n",
    "ax.grid(alpha=0.1)\n",
    "plt.savefig('photometry.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our measurements of stars in the image agree well with the input catalog fluxes at the level of approximately 0.9%. There could be several reasons why we see a small offset between the input and output magnitudes. First, we use a single value of the gain for our zeropoint, but we could do better and use a gain per pixel to convert the image from DN/s to photo-electrons per second and apply the zeropoint (with the gain removed). This would likely decrease the scatter in the plot. Secondly, we used a single aperture correction for the whole image based on the model of a star with an average SED and located at the center of the detector. A more detailed handling of the aperture correction may also decrease the scatter, and may also help bring the measurements into better alignment with the input catalog. Finally, a more careful treatment of other systematics (e.g., interpixel capacitance) may yield even better results.\n",
    "\n",
    "A similar exercise in photometry can be repeated for the galaxies in the input catalog, but care should be taken when selecting apertures for galaxies as fixed aperture sizes will correspond to different physical sizes at the distances of galaxies. Other choices for galaxy apertures include, e.g., Kron apertures or isophotal apertures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "The [Photutils documentation](https://photutils.readthedocs.io/en/stable/) has additional tutorials for detecting and fitting sources in images:\n",
    "\n",
    "- [Aperture photometry](https://photutils.readthedocs.io/en/stable/aperture.html)\n",
    "- [Background estimation](https://photutils.readthedocs.io/en/stable/background.html)\n",
    "- [Source detection](https://photutils.readthedocs.io/en/stable/detection.html)\n",
    "- [PSF photometry](https://photutils.readthedocs.io/en/stable/psf.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About This Notebook\n",
    "\n",
    "**Author:** John F. Wu, Tyler Desjardins\\\n",
    "**Updated On:** 2025-12-24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width=\"100%\" style=\"border:none; border-collapse:collapse;\">\n",
    "  <tr style=\"border:none;\">\n",
    "    <td style=\"border:none; width:180px; white-space:nowrap;\">\n",
    "       <a href=\"#top\" style=\"text-decoration:none; color:#0066cc;\">â†‘ Top of page</a> \n",
    "    </td>\n",
    "    <td style=\"border:none; text-align:center;\">\n",
    "       <img src=\"../../roman_logo.png\" width=\"50\">\n",
    "    </td>\n",
    "    <td style=\"border:none; text-align:right;\">\n",
    "       <img src=\"../../stsci_logo2.png\" width=\"90\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
