{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60f5f465-e3a4-43b4-9eb4-6b43b49212ca",
   "metadata": {},
   "source": [
    "# Calibrating WFI Exposures with RomanCal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620243a9-7836-4594-9c0e-c952166fe365",
   "metadata": {},
   "source": [
    "## Kernel Information and Read-Only Status\n",
    "\n",
    "To run this notebook, please select the \"Roman Research Nexus\" kernel at the top right of your window.\n",
    "\n",
    "This notebook is read-only. You can run cells and make edits, but you must save changes to a different location. We recommend saving the notebook within your home directory, or to a new folder within your home (e.g. <span style=\"font-variant:small-caps;\">file > save notebook as > my-nbs/nb.ipynb</span>). Note that a directory must exist before you attempt to add a notebook to it.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e739398-0b70-40fa-8a46-5319d7066c73",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this notebook is to calibrate Level 1 (L1; uncalibrated ramp cube) data with the Roman WFI science calibration pipeline RomanCal (Python package name `romancal`) to produce Level 2 (L2; calibrated rate image) exposure level data. To learn more, please visit the [RDox pages on the Exposure Level Pipeline](https://roman-docs.stsci.edu/data-handbook-home/roman-stsci-data-pipelines/exposure-level-pipeline) (ELP). We also discuss calibration reference files including how to access and examine them and how to run the pipeline with custom reference files.\n",
    "\n",
    "Details about the Roman data levels, including file naming conventions and file array names and data types, can be found in the RDox article [Data Levels and Products](https://roman-docs.stsci.edu/data-handbook-home/wfi-data-format/data-levels-and-products). \n",
    "\n",
    "A L1 file contains uncalibrated ramps in units of Data Numbers (DN).  L1 files are three-dimensional data cubes, one dimension for time and two dimensions for image coordinates, that are shaped as  arrays with (N resultants, 4096 image rows, 4096 image columns). For a given pixel, a resultant contains either one read or the arithmetic mean of multiple reads. \n",
    "\n",
    "L2 WFI files are calibrated rate images in instrumental units of DN / second.  They are two-dimensional arrays shaped as (4088 image rows, 4088 image columns). Note the smaller image size of L2 files, which is due to the removal of the 4-pixel border of reference pixels around the image during pipeline processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1beac9c",
   "metadata": {},
   "source": [
    "### Local Run Settings\n",
    "\n",
    "If you want to run the notebook in your local machine, refer to the information in [local installation](../../markdown/local-run.md) instructions before proceeding with the notebook. The instructions provide inportant information about setting up your environment and installing dependnecies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a0491-6dcc-475e-9118-e22a9e2a31c2",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Libraries used:\n",
    "- *astropy* for coordinates manipulation and image normalization\n",
    "- *copy* for making copies of Python objects\n",
    "- *crds* for access to calibration reference files\n",
    "- *matplotlib* and *mpl_toolkits* for plotting images\n",
    "- *numpy* for array manipulation\n",
    "- *romancal* for running the Roman WFI science data pipeline\n",
    "- *roman_datamodels* for opening Roman WFI ASDF files\n",
    "- *asdf* for opening Roman WFI ASDF files\n",
    "- *os* for operating system functions\n",
    "- *s3fs* for streaming files from an AWS S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data & Environment Setup ---\n",
    "# This cell configures reference data and environment variables.\n",
    "# On the Roman Research Nexus (RNN), everything is pre-configured and\n",
    "# this cell completes instantly.  For local or CI execution it will\n",
    "# download any missing reference data automatically.\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "REQUIRED_DATA = []\n",
    "\n",
    "# Load the setup module ---------------------------------------------------\n",
    "try:\n",
    "    import notebook_data_dependencies as ndd\n",
    "except ImportError:\n",
    "    # Walk up from the notebook directory to find shared/notebook_data_dependencies.py\n",
    "    _here = Path(os.getcwd())\n",
    "    for _parent in [_here] + list(_here.parents):\n",
    "        _candidate = _parent / 'shared' / 'notebook_data_dependencies.py'\n",
    "        if _candidate.exists():\n",
    "            import importlib.util\n",
    "            _spec = importlib.util.spec_from_file_location('notebook_data_dependencies', _candidate)\n",
    "            ndd = importlib.util.module_from_spec(_spec)\n",
    "            _spec.loader.exec_module(ndd)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            'Cannot find shared/notebook_data_dependencies.py in any parent directory.\\n'\n",
    "            'Make sure you are running from within the roman_notebooks repo.'\n",
    "        )\n",
    "\n",
    "# Download missing reference data (no-op when env vars are already set) ---\n",
    "result = ndd.install_files(packages=REQUIRED_DATA) if REQUIRED_DATA else {}\n",
    "ndd.setup_env(result)  # Sets data paths + CRDS env vars\n"
   ],
   "id": "b79a3f31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4bf0b-4a5d-4aa1-974f-fbc5ca87c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.visualization import simple_norm\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, colormaps as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import roman_datamodels as rdm\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb19274-2253-455f-b116-f49509ab7c3c",
   "metadata": {},
   "source": [
    "### The Calibration Reference Data System (CRDS)\n",
    "\n",
    "The Roman ELP, which corrects L1 images for detector-level effects to produce L2 images, uses calibration reference and parameter files from the [CRDS](https://roman-crds.stsci.edu/static/users_guide/overview.html). These reference files, developed and validated by STScI’s Science Operations Center, are continually updated as new WFI data become available. CRDS assigns the most appropriate reference file for each calibration step using metadata keywords and file-specific matching criteria. To use the best-available reference files for an observation, no action is needed as RomanCal will query for the best reference files for each calibration step in the pipeline.\n",
    "\n",
    "In this tutorial, we will focus on the **[`crds`](https://roman-crds.stsci.edu/static/users_guide/index.html)** Python application programming interface (API). The [**CRDS** webserver](https://roman-crds.stsci.edu) can also be accessed to browse calibration reference files in a tabular interface. Note that there are multiple CRDS servers, though most users will interact with the Operations (OPS) instance. Please be sure to navigate to the correct webserver for the instance in which you are interested.\n",
    "\n",
    "For more details, see the [RDox page on CRDS for Roman WFI](https://roman-docs.stsci.edu/data-handbook-home/accessing-wfi-data/crds-for-reference-files) and the [CRDS documentation](https://jwst-crds.stsci.edu/static/users_guide/web_site_use.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd079d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import romancal packages\n",
    "import romancal\n",
    "from romancal.pipeline import ExposurePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66cc692-6db8-49f8-8db2-4b138391b508",
   "metadata": {},
   "source": [
    "## Tutorial Data\n",
    "\n",
    "In this tutorial, we use L1 WFI data files simulated with Roman I-Sim. As an example, we take the output product from the [Roman I-Sim](../romanisim/romanisim.ipynb) tutorial notebook. If you have not run that simulation, the files are available in the Nexus S3 bucket. For more information on accessing these data, see the [Data Discovery and Access](../data_discovery_and_access/data_discovery_and_access.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3a847-cb53-43e6-ad2b-239222822279",
   "metadata": {},
   "source": [
    "## Running the ELP on L1 Data\n",
    "\n",
    "To run the ELP on L1 data, you have two options:\n",
    "1. **Basic:** Use `romancal.ExposurePipeline()` to run all steps.\n",
    "2. **Advanced:** Run one or more individual steps.\n",
    "\n",
    "### Basic Example: Full Pipeline\n",
    "The input file for this example is a WFI L1 ASDF file. First, we check whether the file is already saved on disk (if the Roman I-Sim tutorial was run). If not, we stream the L1 file into memory (as a datamodel) from the Nexus S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62455c67-ad9f-4566-9d38-12f732e8404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_file = 'r0003201001001001004_0001_wfi01_f106_uncal.asdf'\n",
    "\n",
    "if os.path.exists(l1_file):\n",
    "    dm_l1 = rdm.open(l1_file)\n",
    "else:\n",
    "    s3_uri = asdf_dir_uri = 's3://stpubdata/roman/nexus/soc_simulations/tutorial_data/'\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    dm_l1 = rdm.open(fs.open(s3_uri + l1_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333b7c8-4dfd-4cc3-ad73-72a8642a6aa5",
   "metadata": {},
   "source": [
    "We begin by examining the data type using the `type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e5f96-eeac-44dc-9e08-5f4b2e11cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dm_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda78dff-007b-48e0-8173-ea483ec9f760",
   "metadata": {},
   "source": [
    "Reading the ASDF file with `roman_datamodels` returns a `ScienceRawModel` datamodel, which is the L1 file datamodel. At this point, we can use the `.info()` method on the data to look at the file contents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5e01a-7ea4-42a2-8bac-76a031cbc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_l1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5a645-9b6a-4504-8495-2e856169d731",
   "metadata": {},
   "source": [
    "We can see that this L1 file was created with Roman I-Sim as it contains the \"romanisim\" block.\n",
    "\n",
    "Next, we present a basic example of running the complete pipeline.\n",
    "\n",
    "The optional `save_results` parameter determines whether the resulting L2 datamodel is saved as a file on your Nexus storage. Setting this parameter to `True` enables file saving. In this example, we retain the calibrated L2 datamodel in memory as the variable result without saving it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87c37e-23ef-4d6d-83da-c99ce5bb93a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ExposurePipeline.call(dm_l1, save_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ef673d-d424-4c66-b503-92368c6a979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201736df-4a74-467d-8f81-8baca4f91d31",
   "metadata": {},
   "source": [
    "The output from the Exposure Pipeline is an `ImageModel` object, which serves as the datamodel for L2 files.\n",
    "\n",
    "In addition, the pipeline created three other files in the working directory with names similar to the input L1 file. These files end with `*_cat.parquet`, `*_segm.asdf`, and `*_wcs.asdf`, corresponding to a Level 4 (L4) single-band source catalog, a L4 segmentation map, and a L1 updated WCS file, respectively. The L1 WCS file provides a L2-quality World Coordinate System (WCS) when working with a L1 file, which have a different number of pixels than L2 files, without updating the original L1 file on disk. More information about working with L4 products will be added in another future tutorial. **Note:** L4 products are still being validated and should be used with caution during development.\n",
    "\n",
    "Optional parameters can also be passed to individual pipeline steps through the steps dictionary. For example, the code below demonstrates how to skip both the source catalog step and the step that aligns the image with the Gaia astrometric catalog (the TweakReg step, named after the software used to update the WCS). Other parameters can be configured in the same way; for details, see the [romancal documentation](https://roman-pipeline.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a46f793-4bdd-4fb1-ba2e-28308f9f5ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = ExposurePipeline.call(dm_l1, save_results=False, steps={'source_catalog': {'skip': True}, 'tweakreg': {'skip': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da33cf1-e177-4c66-9a58-198f9d037472",
   "metadata": {},
   "source": [
    "At the end of the pipeline log messages, you will see that the SourceCatalog and TweakReg steps were skipped, as expected. Because the source catalog step was omitted, the L4 source catalog and segmentation map files were not regenerated. To verify the status of a step, you can also inspect the metadata of the output datamodel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87328ce5-1a37-4e46-873e-664c124bfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.meta.cal_step.source_catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d7f60-b0b6-4267-9f3e-b4dc822db067",
   "metadata": {},
   "source": [
    "More information on these steps can be found in the [Exposure Pipeline](https://roman-docs.stsci.edu/data-handbook-home/roman-data-pipelines/exposure-level-pipeline#ExposureLevelPipeline-PipelineStepDescriptions) article on RDox.\n",
    "\n",
    "Note that the ramp-fitting step transforms the structure of the data — in other words, the data models before and after ramp fitting are intrinsically different. Therefore, steps following ramp fitting cannot be applied to data that has not undergone it, and similarly, steps preceding ramp fitting cannot be applied once the data has.\n",
    "\n",
    "We can save our L2 datamodel to disk with the `.save()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540165ac-ffbe-4ae8-ade1-83b2b407db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.save('my_roman_l2_file.asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7111d85-57db-49f6-abac-407f22ffa7e8",
   "metadata": {},
   "source": [
    "If you look at the file browser in the directory where you ran this tutorial, you should see a new file called \"my_roman_l2_file.asdf\". Note that you may need to wait a moment or manually refresh the file browser before it appears."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acec82-fd9d-4f4f-a253-43a1c7883858",
   "metadata": {},
   "source": [
    "### Advanced Example: Running Individual Pipeline Steps\n",
    "\n",
    "Now, for a more advanced use case, let's update the WCS based on the pointing information. For example, suppose we simulated an L1 file, processed it with the ELP, and now want to try shifting the pointing information and creating a new WCS to test the Gaia alignment. After editing any of the `meta.wcsinfo` values we wish to change, we can generate a new WCS by running the AssignWcsStep on our L2 ASDF file.\n",
    "\n",
    "Let's start by reading in a fresh L2 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bd049-a068-4fbb-a9a4-3b883b62207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_file = 'r0003201001001001004_0001_wfi01_f106_cal.asdf'\n",
    "\n",
    "if os.path.exists(l2_file):\n",
    "    dm = rdm.open(l2_file)\n",
    "else:\n",
    "    s3_uri = asdf_dir_uri = 's3://stpubdata/roman/nexus/soc_simulations/tutorial_data/'\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    dm = rdm.open(fs.open(s3_uri + l2_file, 'rb'))\n",
    "    original_wcs = copy.deepcopy(dm.meta.wcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bac03-fa66-44cd-bbb3-1cc9e1a0fdab",
   "metadata": {},
   "source": [
    "Let's take a quick look at the file we just opened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5b886-0e2f-4882-807c-b6bafb37ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68db74-7141-44cf-bd3b-a27e9de7afae",
   "metadata": {},
   "source": [
    "Before aligning the images with the Gaia coordinates, the WCS in an L2 file is populated using the telescope pointing information, resulting in the so-called \"coarse WCS\". The `meta.pointing` section of the metadata describes the spacecraft pointing, while the detector-dependent information used to construct the coarse WCS is contained in the `meta.wcsinfo` section. Although the values in `meta.pointing` and `meta.wcsinfo` are linked, the coarse WCS relies only on `meta.wcsinfo`. Let’s examine our `meta.wcsinfo` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4bf9f-ef0c-43ca-95d7-708969f76891",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.meta.wcsinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb89bc-8c9f-4caf-affe-ebe2ccb5700d",
   "metadata": {},
   "source": [
    "Let's focus on the `ra_ref`, `dec_ref`, and `roll_ref` keywords. Let's first take a look at the descriptions of these fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6afec-054b-4a79-8e43-f697ff47f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ra_ref = {dm.schema_info(path='roman.meta.wcsinfo.ra_ref')['description']}\")\n",
    "print(f\"dec_ref = {dm.schema_info(path='roman.meta.wcsinfo.dec_ref')['description']}\")\n",
    "print(f\"roll_ref = {dm.schema_info(path='roman.meta.wcsinfo.roll_ref')['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26047f-545e-43fa-b586-e6831e380c94",
   "metadata": {},
   "source": [
    "The \"reference pixel position\" mentioned in these descriptions is located at the center of each WFI detector (each detector has its own WCS). We can edit these values to make the pipeline create a WCS solution that is slightly different from the original. Let's make a copy of the data (for comparison later) and apply a simple shift of 1 arcsecond in right ascension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddd8d1-cecf-4d6b-a4d8-ce43a62202a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ra_ref = copy.copy(dm.meta.wcsinfo.ra_ref)\n",
    "dm.meta.wcsinfo.ra_ref += (1 / 3600)\n",
    "\n",
    "print(f'Original ra_ref = {original_ra_ref},\\nUpdated ra_ref = {dm.meta.wcsinfo.ra_ref}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66fb69-8781-498d-800c-da639c113fb1",
   "metadata": {},
   "source": [
    "Next, let's run AssignWcsStep on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e35d74-7383-43b7-832e-9a6bc69eaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = romancal.assign_wcs.AssignWcsStep.call(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba6268-2e75-4db7-8814-869f10085de0",
   "metadata": {},
   "source": [
    "Let’s now verify whether the coordinate system has changed as expected by comparing the right ascension and declination of a given pixel in the two WCS reference systems. For simplicity, we’ll use the center of the L2 image, which corresponds to (x, y) = (2043.5, 2043.5) in 0-indexed pixels. The corresponding sky coordinates can be easily obtained using `astropy.coordinates.SkyCoord` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b7dd4-0857-439c-aed9-b5a584501842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SkyCoord object for new position at center of detector\n",
    "ra, dec = result.meta.wcs(2043.5, 2043.5)\n",
    "result_coord = SkyCoord(ra=ra, dec=dec, unit='deg')\n",
    "result_coord\n",
    "\n",
    "# Get SkyCoord object for original position at center of detector\n",
    "ra0, dec0 = original_wcs(2043.5, 2043.5)\n",
    "original_coord = SkyCoord(ra=ra0, dec=dec0, unit='deg')\n",
    "original_coord\n",
    "\n",
    "# Compute the separation between the updated and original positions\n",
    "result_coord.separation(original_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e616d91-478d-4400-918b-a58ca0e2d79f",
   "metadata": {},
   "source": [
    "As we can see, the newly updated WCS is shifted by approximately 1 arcsecond relative to the WCS in the original L2 file. The offset is not exactly 1 arcsecond because the WFI pixel grid is slightly rotated with respect to the celestial coordinate system. In other words, the detector axes are not perfectly aligned with the vertical (declination) and horizontal (right ascension) directions on the sky.\n",
    "\n",
    "As in our pipeline example above, we can also pass optional arguments to individual steps. This is useful if we want to use our own version, or an older version, of a reference file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2173ffd-1e73-4b17-9b18-fb10ee6181ae",
   "metadata": {},
   "source": [
    "## Reference Files\n",
    "\n",
    "As mentioned above, several of the pipeline steps apply reference files to the data to correct for specific detectors' effects.\n",
    "Common examples of reference files applied during the processing of imaging data include the **Bad Pixel Mask**, **Dark**, and **Flat** (see below details on each). More information on WFI reference file types can be found in the RDox article [CRDS for Reference Files](https://roman-docs.stsci.edu/data-handbook-home/accessing-wfi-data/crds-for-reference-files).\n",
    "\n",
    "**IMPORTANT NOTE:** Reference files are a work in progress and will be updated several times before Roman launch. If you notice irregularities or missing information, please understand that they may be a known issue. If you have questions, please contact the [Roman Help Desk](https://romanhelp.stsci.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0c2b6f-a9b5-493b-aa8f-051c27c1ccc7",
   "metadata": {},
   "source": [
    "### Bad Pixel Masks\n",
    "\n",
    "Bad pixels are masked during the Data Quality (DQ) initialization step.  The MASK reference file, which contains static bad pixel flags (i.e., locations of dead pixels, telegraph pixels, etc.) for each detector, populates the data quality (DQ) `dq` array of the L2 calibrated rate image files after processing by RomanCal. During RomanCal processing, the MASK file is used in the `romancal.dq_init.DQInitStep()` step (the first step in the ELP) to populate an array called `pixeldq` in the RampModel datamodel, which is used within the pipeline. DQ flags are combined with additional DQ flags from reference file DQ arrays during subsequent processing steps using `bitwise_or`.\n",
    "\n",
    "These mask reference files are created from dark or flat calibration datasets. Different types of pixels are flagged based on their pixel values (i.e., dead pixels with significantly reduced detector response) or behavior up-the-ramp (i.e., telegraph pixels jump between two electronic states).\n",
    "\n",
    "For more details, see the [romancal documentation](https://roman-pipeline.readthedocs.io/en/latest/roman/dq_init/index.html) and [Rdox documentation](https://roman-docs.stsci.edu/data-handbook-home/roman-data-pipelines/exposure-level-pipeline#ExposureLevelPipeline-dq_init) for DQ initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5ca61-dfe0-4031-8f4d-172f4a135b52",
   "metadata": {},
   "source": [
    "### Darks \n",
    "\n",
    "The DARK reference file is selected based on the WFI mode (imaging or spectroscopy) used to obtain the science data. During the `romancal.dark_current.DarkCurrentStep()` step, the dark current is subtracted off on a pixel-by-pixel and resultant-by-resultant basis. Pixels that are undefined in the dark reference file will not be subtracted from the science data.\n",
    "\n",
    "The dark reference files are created from dark calibration datasets.  A set of dark files are sigma clipped, and stacked resultant-by-resultant to create a super dark.\n",
    "\n",
    "For more details, see the [romancal documentation](https://roman-pipeline.readthedocs.io/en/latest/roman/dark_current/index.html) and [Rdox documentation](https://roman-docs.stsci.edu/data-handbook-home/roman-data-pipelines/exposure-level-pipeline#ExposureLevelPipeline-dark_current) for dark current subtraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daaf93f-123f-419b-9929-08d3fe6ce032",
   "metadata": {},
   "source": [
    "### Flats\n",
    "\n",
    "The FLAT reference file is selected based on the optical element used to obtain the science data.  It contains the flatfield data which corrects for both large-scale and pixel-to-pixel sensitivity variations, ensuring uniform data for a specific imaging filter.  During the `romancal.flatfield.FlatFieldStep()` step, the science array is divided by the flatfield reference array for the matching filter, effectively \"flattening\" the variations in the data.  Pixels with negative values or that are flagged will be skipped and not updated.\n",
    "\n",
    "The flat reference file is created from flat calibration datasets.  A set of flat exposures with the same filter within some date range to the science data are used to compute flat rate images. These are averaged together and normalized, producing a filter-dependent flat rate image. Spectroscopic mode observations are not flatfielded by RomanCal, and there are no flat reference files available for the WFI grism or prism available from the Science Operations Center at STScI. For grism and prism observations, the flatfield step will be skipped.\n",
    "\n",
    "For more details, see the [romancal documentation](https://roman-pipeline.readthedocs.io/en/latest/roman/flatfield/index.html) and [Rdox documentation](https://roman-docs.stsci.edu/data-handbook-home/roman-data-pipelines/exposure-level-pipeline#ExposureLevelPipeline-flatfield) for flat fielding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3db81-1b7a-448f-a462-16eff6ed8f9a",
   "metadata": {},
   "source": [
    "### Retrieving Reference Files\n",
    "\n",
    "As you run the exposure pipeline, the most up-to-date reference files will be automatically selected for each step. However, if you would like to use a specific reference file, these can be retrieved through the `crds` Python API and the ELP run with those files (more on that later). Let's begin with how to access reference files from CRDS.\n",
    "\n",
    "First, let's start by looking at the `crds.getrecommendations()` function. This function returns a dictionary of file names that match the criteria that you supply. Selection criteria are specified in a dictionary of key-value pairs. Each Roman WFI metadata keyword in the dictionary is all-caps and always begins with \"ROMAN.META.\". The remaining parts of the string correspond to the metadata keyword locations in the science data file schema. Different reference file types require different combinations of science metadata to match to the reference files. In general, all reference file types will require the instrument name (\"INSTRUMENT.NAME\") and start time (\"EXPOSURE.START_TIME\"). Most file types require the detector name (\"INSTRUMENT.DETECTOR\"), and some file types require the exposure type (\"EXPOSURE.TYPE\") or optical element (\"INSTRUMENT.OPTICAL_ELEMENT\").\n",
    "\n",
    "For the mask, dark, and flat files in particular, the required keywords are:\n",
    "- mask\n",
    "    - ROMAN.META.INSTRUMENT.NAME\n",
    "    - ROMAN.META.INSTRUMENT.DETECTOR\n",
    "    - ROMAN.META.EXPOSURE.START_TIME\n",
    "- dark\n",
    "    - ROMAN.META.INSTRUMENT.NAME\n",
    "    - ROMAN.META.INSTRUMENT.DETECTOR\n",
    "    - ROMAN.META.EXPOSURE.TYPE\n",
    "    - ROMAN.META.EXPOSURE.START_TIME\n",
    "- flat\n",
    "    - ROMAN.META.INSTRUMENT.NAME\n",
    "    - ROMAN.META.INSTRUMENT.DETECTOR\n",
    "    - ROMAN.META.INSTRUMENT.OPTICAL_ELEMENT\n",
    "    - ROMAN.META.EXPOSURE.START_TIME\n",
    "\n",
    "These keywords may be combined into a single dictionary to find multiple reference file types using `crds.getreferences()`. For example, if you would like to find the name of the dark and flat reference files used by the pipeline, you could run the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3dc8a-bcb3-4948-8d6d-0ccf99c2ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'ROMAN.META.INSTRUMENT.NAME': 'WFI',\n",
    "        'ROMAN.META.INSTRUMENT.DETECTOR': 'WFI01',\n",
    "        'ROMAN.META.INSTRUMENT.OPTICAL_ELEMENT': 'F158',\n",
    "        'ROMAN.META.EXPOSURE.TYPE': 'WFI_IMAGE',\n",
    "        'ROMAN.META.EXPOSURE.START_TIME': '2024-01-01 00:00:00'\n",
    "       }\n",
    "\n",
    "ref_files = crds.getrecommendations(meta, reftypes=['mask', 'dark', 'flat'], observatory='roman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec8fd5-c73a-488a-86ad-52d032dd543c",
   "metadata": {},
   "source": [
    "The `ref_files` variable now contains a dictionary for each of the reference file types you requested (MASK, DARK, and FLAT). These are the reference files that correspond to a science observation taken at midnight UTC on January 1, 2024 in the WFI imaging mode with optical element F158 and detector WFI01. Let's take a look at the names of the files CRDS returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5933f4-2af7-4106-b2ab-a89b7a8fd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916910d-6152-4db7-abfd-e69a3d3e8eac",
   "metadata": {},
   "source": [
    "We can also use `crds.getreferences()` to accomplish the same thing; however, `getreferences()` goes one step further beyond `getrecommendations()` and will download the reference files if they are not already in your local cache. Using the same example as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c9bd3-57a5-4fbf-87ce-ebcf22ac999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'ROMAN.META.INSTRUMENT.NAME': 'WFI',\n",
    "        'ROMAN.META.INSTRUMENT.DETECTOR': 'WFI01',\n",
    "        'ROMAN.META.INSTRUMENT.OPTICAL_ELEMENT': 'F158',\n",
    "        'ROMAN.META.EXPOSURE.TYPE': 'WFI_IMAGE',\n",
    "        'ROMAN.META.EXPOSURE.START_TIME': '2024-01-01 00:00:00'\n",
    "       }\n",
    "\n",
    "ref_files = crds.getreferences(meta, reftypes=['mask', 'dark', 'flat'], observatory='roman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dab9f-c70d-44cb-b6b8-932918e97e49",
   "metadata": {},
   "source": [
    "And once again we can examine the output of `ref_files`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffe7a81-c9cf-4750-a962-41a52dff27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7dd229-a1a7-4455-b020-b224a9c8af7d",
   "metadata": {},
   "source": [
    "This time, `ref_files` contains the path to the file in the local cache (controlled by the `CRDS_PATH` environment variable) since we did not simply ask for the file name but also checked if the file was in our cache, and if it was not then we downloaded it.\n",
    "\n",
    "### CRDS Mapping Files\n",
    "\n",
    "CRDS organizes the reference files using mapping files. The first mapping file, the IMAP, simply describes the instruments available for the observatory. In this case, we use the WFI IMAP and no action is needed by the user to select this. The PMAP file (commonly referred to as the CRDS context) is set by the the `CRDS_CONTEXT` environment variable. The context is also CRDS server-dependent, which is set by the environment variable `CRDS_SERVER_URL`. Let's look at the values for both of those in this environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ea7787-8c96-4f33-97b3-bd50609c9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CRDS server location: {os.environ.get('CRDS_SERVER_URL')}\")\n",
    "print(f\"CRDS context file: {os.environ.get('CRDS_CONTEXT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f0791-745a-4510-929b-103dbd9db28f",
   "metadata": {},
   "source": [
    "The PMAP file contains the name of the IMAP and a list of RMAP file names as well as their contents. The RMAP files, one for each reference file type, list the names of the reference files and their selection criteria, which matches them to science observations. For more information on the mapping rules, see the [readthedocs documentation](https://roman-crds.stsci.edu/static/users_guide/rmap_syntax.html). Let's take a look at our PMAP file first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b9e96-372b-430e-aebc-685425eeee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = crds.rmap.load_mapping(os.environ.get('CRDS_CONTEXT'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b79b7-3163-45f2-a455-09e12f20b0cc",
   "metadata": {},
   "source": [
    "This `pmap` object contains all of the mapping information for every reference file in this context. This is a lot to look at, so let's get the names of the mapping files contained within so we can look at one more closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595a02a-2b18-48ed-ab94-0324a58023f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = pmap.mapping_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c1634-b530-48d4-83a5-baaad241c73a",
   "metadata": {},
   "source": [
    "Now let's isolate the name of just the MASK rmap. We can pick the name above, but here we show how to do this programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9b0d9-f49e-4bc6-b2fd-1bd76ec8fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in maps:\n",
    "    if 'mask' in m:\n",
    "        mask_rmap = m \n",
    "        break\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "masks = crds.rmap.load_mapping(mask_rmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac06519-5fb8-47c4-a952-ffc5c15e9877",
   "metadata": {},
   "source": [
    "Now that we have loaded up the RMAP, let's take a look at it using the `todict()` method to turn it into a dictionary we can more easily visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0628107-18a9-47c7-a0c9-58f4aa01aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.todict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb51f1-3e83-4f00-b95d-375fd6fa4226",
   "metadata": {},
   "source": [
    "The `parkey` key tells us the matching criteria unique to this reference file type from the dictionary we created when we used `crds.getrecommendations()` and `crds.getreferences()` (not shown are matching criteria always required by CRDS). Also notice that the `parameters` field tells us the column names for the `selections` part of the dictionary. In this case, we see they include \"ROMAN.META.INSTRUMENT.DETECTOR\", \"USEAFTER\", and \"REFERENCE\". The REFERENCE column is simply the name of the reference file that matches those critiera. The USEAFTER date is the date after which a file should be used for a science observation. CRDS will match the file with the closest **preceding** USEAFTER date to the science observation date (given by \"ROMAN.META.EXPOSURE.START_TIME\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b7a3f5-57df-47bc-af5c-fc64812ffa06",
   "metadata": {},
   "source": [
    "### Download a File by Name\n",
    "\n",
    "If you know the specific reference file name and would like to download it directly from the CRDS on-premise server, you can call it via a command line option:\n",
    "\n",
    "```\n",
    "crds sync --files <filename> --output-dir=<pathname>\n",
    "```\n",
    "\n",
    "where `<filename>` is the name of the reference file (e.g. \"roman_wfi_mask_0022.asdf\") and `<pathname>` is the location where the file will be saved. **Note:** in the future, Roman reference files will also be available via an AWS S3 bucket, and these instructions will be updated to describe how to access them there. \n",
    "\n",
    "To run this in a Jupyter notebook, we write out the command as a string and pass it to the command line script code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b8142-d912-419a-ba43-635beb87995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"crds.sync --files {ref_files['mask']}\"\n",
    "_ = crds.sync.SyncScript(cmd)()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b65450-a2e1-40c6-ab75-144c28480778",
   "metadata": {},
   "source": [
    "In this case, nothing happened since we had already previously downloaded this file into our cache using `crds.getreferences()`. But if you know the file name of a reference file that you want to retrieve from CRDS without using the matching criteria, the cell above would download the file to your cache. Simply replace `{ref_files['mask']}` in the `cmd` string with the name of the ASDF file.\n",
    "\n",
    "### Examining Reference Files\n",
    "\n",
    "Reference files use `roman_datamodels` just like WFI science data products and can be accessed in the same way (see the tutorial [Working with ASDF](../working_with_asdf/working_with_asdf.ipynb) for more information). Let's take a closer look at the files we retrieved from our `crds.getreferences()` example starting with the mask file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad3211-188d-45ef-b5f1-2ef6bf466450",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = rdm.open(ref_files['mask'])\n",
    "mask.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf654d4c-522d-473e-b016-6b9a19be539d",
   "metadata": {},
   "source": [
    "We see that the mask file contains metadata and a single array called `dq`. If we display the `dq` array, then we can see all of the features that have been flagged. The [Working with ASDF](../working_with_asdf/working_with_asdf.ipynb) tutorial gives more information about how to parse the meanings of the DQ flags. For now, let's plot two versions of the file, one with each bitwise sum of DQ flags on a color map and another flattened version with \"good\" (DQ = 0; black pixels in the right-hand panel of the plot below) and \"bad\" (DQ >= 1; white pixels in the right-hand panel of the plot below) flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f4ca3-a00b-4c32-90a6-40c406f2b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 14))\n",
    "\n",
    "# Make a copy of the colormap so we can reset non-finite numbers to black\n",
    "my_cmap = copy.copy(cm.get_cmap('nipy_spectral'))\n",
    "my_cmap.set_bad((0, 0, 0))\n",
    "\n",
    "# Display the mask file with a log normalization using the updated color map\n",
    "im = axs[0].imshow(mask.dq, origin='lower', norm=colors.LogNorm(vmin=1, vmax=5e5), cmap=my_cmap)\n",
    "divider = make_axes_locatable(axs[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "axs[0].set_xlabel('Science X (pixels)')\n",
    "axs[0].set_ylabel('Science Y (pixels)')\n",
    "axs[0].set_title('Color-Coded DQ Flags')\n",
    "fig.colorbar(im, cax=cax)\n",
    "\n",
    "# Display the mask file with boolean good and bad values on a grayscale map\n",
    "axs[1].imshow(np.bool(mask.dq), origin='lower', cmap='binary_r')\n",
    "axs[1].set_xlabel('Science X (pixels)')\n",
    "axs[1].set_ylabel('Science Y (pixels)')\n",
    "axs[1].set_title('Good vs Bad Flags')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a644e-96f8-4ba9-8e19-0b4247e04086",
   "metadata": {},
   "source": [
    "Note that not all DQ flags > 0 are necessarily bad. Many DQ flags are informational about detector effects or note something about the data processing. It is important for you to decide what effects are important for your science case.\n",
    "\n",
    "Next, we'll take a look at a dark. This isn't as visually interesting for the WFI as the dark current is so low, so we will simply display the file information and discuss the contents.\n",
    "\n",
    "**Note:** Dark reference files from the Science Operations Center at STScI are still being developed. The dark files currently in CRDS are placeholders with all-zero values to enable simulations and pipeline processing. Updated darks are expected in early 2026."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac202f15-eb61-4efe-81d3-835e7f06e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark = rdm.open(ref_files['dark'])\n",
    "dark.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a3635-5642-48b8-9c96-f4a6f9d758ee",
   "metadata": {},
   "source": [
    "In addition to metadata, we see there are several arrays. The `data` array contains a cube of dark values up-the-ramp. This is used in the current version of the ELP, however changes are being made towards a dark rate subtraction post-ramp-fitting. The `dark_slope` array contains the dark rate per pixel, and the `dark_slope_error` is the uncertainty in the dark rate. Finally, a `dq` array is present to flag effects in the dark current (such as hot pixels).\n",
    "\n",
    "Finally, let's examine a flat reference file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6565930-b344-4b4b-9a1d-492ff463301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = rdm.open(ref_files['flat'])\n",
    "flat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868eed54-c552-4324-bae3-4622ef81c4a9",
   "metadata": {},
   "source": [
    "Once again, we see a `data` array, which in this case is the flatfield values, a `dq` array for flagging effects in the flatfield, and an `error` array. Let's take a look at the flatfield for this detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732d453-7394-4fec-b0e9-e9111a243e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(14, 14))\n",
    "\n",
    "norm = simple_norm(flat.data, percent=99.5)\n",
    "data = axs[0].imshow(flat.data, cmap='gray', norm=norm, origin='lower')\n",
    "axs[0].set_xlabel('Science X (pixels)')\n",
    "axs[0].set_ylabel('Science Y (pixels)')\n",
    "axs[0].set_title('Flatfield')\n",
    "divider = make_axes_locatable(axs[0])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(data, cax=cax)\n",
    "\n",
    "norm = simple_norm(flat.err, percent=99.5)\n",
    "err = axs[1].imshow(flat.err, cmap='gray', norm=norm, origin='lower')\n",
    "axs[1].set_xlabel('Science X (pixels)')\n",
    "axs[1].set_ylabel('Science Y (pixels)')\n",
    "axs[1].set_title('Flatfield Error')\n",
    "divider = make_axes_locatable(axs[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(err, cax=cax)\n",
    "\n",
    "axs[2].imshow(np.bool(flat.dq), cmap='binary_r', origin='lower')\n",
    "axs[2].set_xlabel('Science X (pixels)')\n",
    "axs[2].set_ylabel('Science Y (pixels)')\n",
    "axs[2].set_title('Flatfield DQ')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05fca77-b2c7-420c-9ea0-6dff497e5f4e",
   "metadata": {},
   "source": [
    "## How to Override RomanCal with Local Reference Files\n",
    "\n",
    "If you have a local reference file that you would like to use in RomanCal processing, either one you retrieved from CRDS or one that you made yourself, then you can supply that when you run the ELP as an optional argument. The new reference file you indicate will override the CRDS best reference file selection from the server. Each reference file type has its own override parameter name (e.g., `override_mask`) and must be passed as arguments to the relevant step. Let's look at an example now where we run the pipeline and override the mask and flat files. First, we need new reference files to use. For this example, let's run `crds.getreferences()` and get new files for a different set of observation parameters, and then we can use those to override the best references. Our example is generally a bad idea, but for real applications you will likely already have a file on your disk storage that you want to use. Our example is to show how to override the reference file selection.\n",
    "\n",
    "For our example, we will process a WFI01 L1 file with the ELP, but we will override the mask and flat files to be those from WFI04. Again, **this is not recommended** but simply designed to show how to override the reference file selection used by the pipeline if you have your own calibration reference files you want to use.\n",
    "\n",
    "**Note:** In `romancal` version 0.20.2 (August 2025), there is a bug when overriding reference files. Please make sure to disable the source catalog and tweakreg steps (as shown below) when overriding reference files to bypass this bug. This bug is already fixed in the next `romancal` version (0.21.0; November 2025), which is undergoing testing and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730939f2-c4be-4e67-abf6-81d160140391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = {'ROMAN.META.INSTRUMENT.NAME': 'WFI',\n",
    "        'ROMAN.META.INSTRUMENT.DETECTOR': 'WFI04',\n",
    "        'ROMAN.META.INSTRUMENT.OPTICAL_ELEMENT': 'F158',\n",
    "        'ROMAN.META.EXPOSURE.START_TIME': '2024-01-01 00:00:00'\n",
    "       }\n",
    "\n",
    "ref_files = crds.getreferences(meta, reftypes=['mask', 'flat'], observatory='roman')\n",
    "\n",
    "result = ExposurePipeline.call(dm_l1, save_results=False, steps={\n",
    "                'source_catalog': {'skip': True},\n",
    "                'tweakreg': {'skip': True},\n",
    "                'dq_init': {'override_mask': ref_files['mask']},\n",
    "                'flatfield': {'override_flat': ref_files['flat']}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c922378-8310-47dd-a1d6-36caea2b6340",
   "metadata": {},
   "source": [
    "Now let's take a look at our `result` variable, which is our L2 datamodel in memory. Specifically, we can check the `meta.ref_file` section to see the names of the reference files used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f157f-6d4a-4dd9-bbcf-3cd060bbc51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in result.meta.ref_file.items():\n",
    "    print(f'{k} = {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533cbc5-fbab-4b1f-93d2-aecb34c033c0",
   "metadata": {},
   "source": [
    "Indeed, we see that many of the files used came from CRDS (note the file names begin with \"crds://\") whereas the flat and mask files contain a local path to the files we selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9a36d6",
   "metadata": {},
   "source": [
    "## About this Notebook\n",
    "**Author:** T. Desjardins.\n",
    "\n",
    "**Updated On:** 2025-12-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb919f",
   "metadata": {},
   "source": [
    "<table width=\"100%\" style=\"border:none; border-collapse:collapse;\">\n",
    "  <tr style=\"border:none;\">\n",
    "    <td style=\"border:none; width:180px; white-space:nowrap;\">\n",
    "       <a href=\"#top\" style=\"text-decoration:none; color:#0066cc;\">↑ Top of page</a> \n",
    "    </td>\n",
    "    <td style=\"border:none; text-align:center;\">\n",
    "       <img src=\"../../roman_logo.png\" width=\"50\">\n",
    "    </td>\n",
    "    <td style=\"border:none; text-align:right;\">\n",
    "       <img src=\"../../stsci_logo2.png\" width=\"90\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
