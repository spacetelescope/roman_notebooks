{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Visualization of Roman APT products\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Server Information\n",
    "IMPORTANT: To run this tutorial, please make sure you are logged in the RRN with a medium or large server. Running the parallelized examples in the advanced use cases will require a large server.\n",
    "\n",
    "\n",
    "## Kernel Information and Read-Only Status\n",
    "\n",
    "To run this notebook, please select the \"Roman Calibration\" kernel at the top right of your window.\n",
    "\n",
    "This notebook is read-only. You can run cells and make edits, but you must save changes to a different location. We recommend saving the notebook within your home directory, or to a new folder within your home (e.g. <span style=\"font-variant:small-caps;\">file > save notebook as > my-nbs/nb.ipynb</span>). Note that a directory must exist before you attempt to add a notebook to it.\n",
    "\n",
    "## Imports\n",
    "\n",
    "- *numpy* to handle array functions\n",
    "- *matplotlib* for plotting data\n",
    "- *astropy.table* for creating tidy tables of the data\n",
    "- *pandas* for creating tidy tables of the data\n",
    "- *pysiaf* to get the coordinates of WFI in different frames of reference (used internally in `footprint_utils`)\n",
    "- *healpy* to generate all-sky maps (used internally in `footprint_utils`)\n",
    "- *hpgeom* to handle quick healpix operations (used internally in `footprint_utils`)\n",
    "- *healsparse* to generate lightweight partial-sky high-resolution HEALPix maps\n",
    "- *skyproj* to generate sky plots using different projections\n",
    "- *dask* (Optional) to perform parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook tries to illustrate several examples of how to visualize APT products in Python. Note that the APT GUI already has Aladdin visualization, and the tool presented in this notebook is complementary.\n",
    "\n",
    "The utility functions defined in `footprint_utils.py` use one of the following APT special outputs:\n",
    "\n",
    "* A pointings file -- this file includes the pointing information from all pointing positions in a given APT program.\n",
    "* A simulator input file -- this file, originally intended to work as input for Roman's image simulation software: `romanIsim`, contains information about all exposures and the position of the `WFI_CEN` aperture, together with duration, and filter element.\n",
    "\n",
    "\n",
    "On this notebook we will demonstrate how to visualize both. Additionally, we will demonstrate how to build these visualizations serially or in parallel. Note: In order to take full advantage of parallelization, the parameters (number of threads / number of processes) need to be optimized according to the machine and inputs used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two packages that will be used throughout the notebook are `healsparse` and `skyproj`. If you want to install these, please uncomment the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install healpy\n",
    "!pip install healsparse\n",
    "!pip install skyproj\n",
    "!pip install dask[complete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from footprint_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import astropy.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import healsparse as hsp\n",
    "import skyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default this notebook will allow you to produce interactive plots, however, some of the plots presented here could lead to reduced performance in certain systems. In order to generate static plots, please the `interactive` variable below to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = True\n",
    "if interactive:\n",
    "    %matplotlib widget\n",
    "else:\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating and loading APT outputs\n",
    "\n",
    "The [Astronomer's Proposal Tool (APT)](https://www.stsci.edu/scientific-community/software/astronomers-proposal-tool-apt) allows the user to design a General Astrophysics Survey with the Wide Field Instrument, and it was used to design the Roman's Core Community Surveys. Given an APT program, the user can export a variety of products using the command line. In this notebook we will focus on two products: the `pointings` file, and the `simulator input` file.\n",
    "\n",
    "In order to export these files the user can execute the following command in a terminal:\n",
    "\n",
    "`PATH_TO_APT_PARENT_DIRECTORY/bin/apt -export pointing,sim PATH_TO_APT_FILE/my_apt_file.apt -nogui -output PATH_TO_OUTPUT_DIRECTORY`\n",
    "\n",
    "This command will generate a pointings file: `my_apt_file.pointing` and a simulator input file: `my_apt_file.sim.ecsv`. In the next sections we will describe what these files contain and how to read them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with `pointing` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a pointings file\n",
    "\n",
    "A pointings file contains information about all survey steps, mosaic patterns and region targets defined in a program. For more information about these concepts we encourage the user follow the Roman documentation ([RDox](https://roman-docs.stsci.edu)). In `footprint_utilities` we define a parsing function to interpret these pointing files. The `read_pointings_file` function reads a pointings file as produced by APT and returns two `pandas.DataFrame` objects, that below we will name `obs_all`, and `reg_all`. The first DataFrame, `obs_all` in our case, encodes the observing strategy of a single mosaic segment (see RDox for more information: https://roman-docs.stsci.edu) on each survey step. The second one, `reg_all` in our case, contains the reference pointing positions (`ra_ref, dec_ref, PA`) of the `WFI_CEN` aperture for each segment in all of the region targets defined in the APT program that was used to create the `.pointing` file.\n",
    "\n",
    "Below, we use an example `pointing` file resulting from an early version of Roman's High-Latitude Wide-Area Survey. However, the parser function should work for any `pointing` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_all, reg_all = read_pointings_file('./aux_data/roman_hlwas.pointing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `obs_all` DataFrame describes the mosaic patterns for a single segment in a Survey Step (given by the `Step` column). The `Tile` column gives the information about the tile number in the mosaic, and `Exposure` is the dither number of each tile. `V2`, and `V3` are referred to the original reference position in arcsec. This DataFrame also contains Ideal offset from the dither (`Dither_X, Dither_Y`), Ideal subpixel dither offset (`Subpixel_X, Subpixel_Y`), the dither distance with respect to the reference point `dDist`, ideal offset from the mosaic (or tile size if calculated from the dimensions of the aperture -- `Tile_X, Tyle_Y`, and Total ideal offset treated as being in the pointing aperture ideal frame (`Total_X, Total_Y`). For more information about the different appertures and conventions we recommend reading the [RDox](https://roman-docs.stsci.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reg_all` DataFrame includes the `Region` name, the RA, and Dec position of the reference point of the Region, which are expressed in the `ra_ref`, `dec_ref` columns (i.e., the center of the Region itself, do not confuse this with the reference point for each segment). The `RA` of the center of the segment (in degrees), the `Dec` of the center of the segment (in degrees) and the `V2` and `V3` angles in arcsec with respect to the reference point of the region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing `pointing` files\n",
    "\n",
    "In the `obs_all` and `reg_all` dataframes we have encoded all the pointing positions in the APT program used to generate the pointings file that we have read. Now we want to visualize these. \n",
    "A convenient way to represent and manipulate the information contained in these pointings file is to build `healsparse` maps (more info at: https://healsparse.readthedocs.io). These are sparse representations of `HEALPix` maps (i.e., the do not carry in memory regions of the sky that are not observed, which is convenient for high-resolution, small-area maps). The `skyproj` (more info at: https://skyproj.readthedocs.io) package has convenient function to visualize these maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in order to visualize the observing strategy of a certain region, a certain pass, or the observations on a given filter, we need to connect the `obs_all` and `reg_all` dataframes with information that is not (currently) available on either of these objects (nor in the pointings file itself). So we need to go the the APT GUI, open the original program, and see which Survey Step corresponds to which target / filter combination. In this example we are going to focus on visualizing one (out of two) of the regions of the HLWAS Medium tier, and we are interested in visualizing the number of exposures in the F129 filter. In our particular case, going to the APT file we see that the first pass corresponds to Survey Step 95 (see screenshot below). The second pass corresponds to Survey Step 96.\n",
    "\n",
    "<img src=\"./aux_data/screenshot.png\" width=\"800\" height=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select only observations that correspond to Step 95 (first pass)\n",
    "obs_filter = (obs_all['Step'] == 95) \n",
    "reg_filter = reg_all['Region'] == 'HLWAS-medium-field1\\n'\n",
    "print('Number of exposures per segment:', np.count_nonzero(obs_filter))\n",
    "print('Number of segments:', np.count_nonzero(reg_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to perform a `for` loop that, for every segment in that region (i.e., reg_all[reg_filter]), goes over all the exposures in said segment (i.e., the observations in `obs_all[obs_filter]`.\n",
    "\n",
    "So, a given entry in `reg_all[reg_filter]` will contain the reference position for one segment, and we will use the `v2, v3` information in `obs_all[obs_filter]` to build the full mosaic in the segment.\n",
    "\n",
    "We show an example below and execute this serially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_ref0, dec_ref0, pa_ref0 = reg_all[reg_filter]['RA'].values[0], reg_all[reg_filter]['Dec'].values[0], reg_all[reg_filter]['PA'].values[0]\n",
    "map_all = None\n",
    "flip = -1  # In APT v.2025.4 the sign of V2, V3 are flipped with respect to the `pysiaf` convention\n",
    "nside_cov = 64  # Nside for coverage map -- set it a low number if the region of the sky to be covered is large\n",
    "nside_sparse = 8192  # Nside for the high-resolution map -- the larger the number the higher the resolution of the map, but the more memory is needed\n",
    "\n",
    "for v2, v3 in zip(obs_all[obs_filter]['V2'].values, obs_all[obs_filter]['V3'].values):\n",
    "    map_here = build_single_exp_map_ref(ra_ref0, dec_ref0, pa_ref0, \n",
    "                                        flip*v2, flip*v3,\n",
    "                                        nside_cov, nside_sparse)\n",
    "    if map_all is None:\n",
    "        map_all = map_here\n",
    "    else:\n",
    "        map_all = hsp.sum_union([map_all, map_here])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "sp = skyproj.McBrydeSkyproj(ax=ax)\n",
    "\n",
    "# We define here a custom colorbar for illustration purposes\n",
    "cmap = plt.cm.Blues  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0, 4, 5)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "# Note that the default is to zoom in to the range defined by the map\n",
    "_ = sp.draw_hspmap(map_all, cmap=cmap, norm=norm)\n",
    "# Set up the colorbar\n",
    "cbar, _ = sp.draw_inset_colorbar(label='Number of exposures', height='3%', bbox_to_anchor=(-0.06, 0.01, 1, 1), loc=4, ticks=[1, 2, 3])\n",
    "cbar.ax.set_xticklabels(['1', '2', '3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With large programs execute these loops serially becomes cumbersome, since each segment is independent, this is a simple-to-parallelize problem. We include an example of how to do so below.\n",
    "\n",
    "In this case we will use `dask`, and the helper function `partial` in order to compress the arguments of\n",
    "`build_single_exp_map_ref`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress, as_completed\n",
    "import dask.array as da\n",
    "import dask\n",
    "from functools import partial\n",
    "client = Client(processes=True)  # In some instances processes=False will perform better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a list with all of the ra, dec, pa positions for the reference\n",
    "\n",
    "ra_ref_all = reg_all[reg_filter]['RA'].values\n",
    "dec_ref_all = reg_all[reg_filter]['Dec'].values\n",
    "pa_ref_all = reg_all[reg_filter]['PA'].values\n",
    "\n",
    "# Collect all v2, v3 from our observations\n",
    "\n",
    "v2_all = obs_all[obs_filter]['V2'].values\n",
    "v3_all = obs_all[obs_filter]['V3'].values\n",
    "\n",
    "# Repeat them and construct an array with nsegments x nexp\n",
    "\n",
    "ra_ref_all = ra_ref_all[:, None] * np.ones(v3_all.shape[0])\n",
    "dec_ref_all = dec_ref_all[:, None] * np.ones(v3_all.shape[0])\n",
    "pa_ref_all = pa_ref_all[:, None] * np.ones(v3_all.shape[0])\n",
    "\n",
    "v2_all = v2_all[None, :] * np.ones(ra_ref_all.shape[0])[:, None]\n",
    "v3_all = v3_all[None, :] * np.ones(ra_ref_all.shape[0])[:, None]\n",
    "\n",
    "# Flatten to pass to our multiprocessing function\n",
    "\n",
    "ra_ref_all = da.from_array(ra_ref_all.flatten())\n",
    "dec_ref_all = da.from_array(dec_ref_all.flatten())\n",
    "pa_ref_all = da.from_array(pa_ref_all.flatten())\n",
    "v2_all = da.from_array(v2_all.flatten())\n",
    "v3_all = da.from_array(v3_all.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mapping task for building exposures for each single exposure\n",
    "map_here = client.map(partial(build_single_exp_map_ref, nside_sparse=nside_sparse, nside_cov=nside_cov), ra_ref_all,\n",
    "                       dec_ref_all, pa_ref_all, v2_all, v3_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all together\n",
    "total = client.map(hsp.sum_union, [map_here])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create progress bar and compute\n",
    "progress(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view of the result in a variable (or compute and bring to memory if it has not been computed on the previous step)\n",
    "map_new = total[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2, figsize=(8, 6))\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "sp = skyproj.McBrydeSkyproj(ax=ax)\n",
    "\n",
    "# We define here a custom colorbar for illustration purposes\n",
    "cmap = plt.cm.Blues  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0, 4, 5)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "# Note that the default is to zoom in to the range defined by the map\n",
    "_ = sp.draw_hspmap(map_new, cmap=cmap, norm=norm)\n",
    "# Set up the colorbar\n",
    "cbar, _ = sp.draw_inset_colorbar(label='Number of exposures', height='3%', bbox_to_anchor=(-0.06, -0.1, 1, 1), loc=1, ticks=[1, 2, 3])\n",
    "cbar.ax.set_xticklabels(['1', '2', '3'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more example, now with two passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_filter = (obs_all['Step'] == 95) | (obs_all['Step'] == 96)\n",
    "reg_filter = reg_all['Region'] == 'HLWAS-medium-field1\\n'\n",
    "print('Number of exposures per segment:', np.count_nonzero(obs_filter))\n",
    "print('Number of segments:', np.count_nonzero(reg_filter))\n",
    "\n",
    "# First we create a list with all of the ra, dec, pa positions for the reference\n",
    "\n",
    "ra_ref_all = reg_all[reg_filter]['RA'].values\n",
    "dec_ref_all = reg_all[reg_filter]['Dec'].values\n",
    "pa_ref_all = reg_all[reg_filter]['PA'].values\n",
    "\n",
    "# Collect all v2, v3 from our observations\n",
    "\n",
    "v2_all = obs_all[obs_filter]['V2'].values\n",
    "v3_all = obs_all[obs_filter]['V3'].values\n",
    "\n",
    "# Repeat them and construct an array with nsegments x nexp\n",
    "\n",
    "ra_ref_all = ra_ref_all[:, None] * np.ones(v3_all.shape[0])\n",
    "dec_ref_all = dec_ref_all[:, None] * np.ones(v3_all.shape[0])\n",
    "pa_ref_all = pa_ref_all[:, None] * np.concatenate([np.ones(v3_all.shape[0]//2), np.ones(v3_all.shape[0]//2)*227/60])  # Trick to force the second pass to PA=227 -- feature from APT 2025.4 exporter\n",
    "\n",
    "v2_all = v2_all[None, :] * np.ones(ra_ref_all.shape[0])[:, None]\n",
    "v3_all = v3_all[None, :] * np.ones(ra_ref_all.shape[0])[:, None]\n",
    "\n",
    "\n",
    "# Flatten to pass to our multiprocessing function\n",
    "\n",
    "ra_ref_all = da.from_array(ra_ref_all.flatten())\n",
    "dec_ref_all = da.from_array(dec_ref_all.flatten())\n",
    "pa_ref_all = da.from_array(pa_ref_all.flatten())\n",
    "v2_all = da.from_array(v2_all.flatten())\n",
    "v3_all = da.from_array(v3_all.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reuse the client\n",
    "map_here = client.map(partial(build_single_exp_map_ref, nside_sparse=nside_sparse, nside_cov=nside_cov), ra_ref_all,\n",
    "                       dec_ref_all, pa_ref_all, v2_all, v3_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = client.map(hsp.sum_union, [map_here])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_new = total[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(3, figsize=(8, 6))\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "sp = skyproj.McBrydeSkyproj(ax=ax)\n",
    "\n",
    "# We define here a custom colorbar for illustration purposes\n",
    "cmap = plt.cm.Blues  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0, 7, 8)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "# Note that the default is to zoom in to the range defined by the map\n",
    "_ = sp.draw_hspmap(map_new, cmap=cmap, norm=norm)\n",
    "# Set up the colorbar\n",
    "cbar, _ = sp.draw_inset_colorbar(label='Number of exposures', height='3%', bbox_to_anchor=(-0.06, -0.1, 1, 1), loc=1, ticks=[1, 3, 6])\n",
    "cbar.ax.set_xticklabels(['1', '3', '6'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non uniformities are caused by the fact that the region tiling has been defined using the original PA angle (60 degrees). For future versions this will be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with simulator input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a simulator input file `sim.ecsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulator input file `*.sim.ecsv` is an output from APT intended to be used as input in `romanisim` to generate simulated images. It contains information about the position `RA, Dec` of the `WFI_CEN` aperture for eaach exposure in the program, together with information about the filter element used, and the duration in seconds (Note: duration is not exposure time, but exposure time + potential slew times / estimated overheads). These files are in `ecsv` format so they can easily be read by `pandas` or `astropy` (recommended for automatic parsing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_table = astropy.table.Table.read('./aux_data/roman_hlwas.sim.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we opted to use `astropy` and got an `astropy.table.Table` object that contains the `RA, DEC, PA` of the `WFI_CEN` aperture. The filter element is displayed in the `BANDAPASS` column. The `MA_TABLE_NUMBER` column indicates the identification number of the MultiAccum table. The `DURATION` column indicates the duration of the exposure including overheads (slews + readout, etc). `PLAN` is the plan number. `PASS` corresponds to `Survey Step` in APT. `SEGMENT` corresponds to the segment number. `OBSERVATION` corresponds to the observation number in a survey step (i.e., the pass number in a survey step and it matches `Observation` in the `obs_all` DataFrame). `VISIT` corresponds to the `Tile` number in the mosaic segment (in the `obs_all` DataFrame). Finally, `EXPOSURE` is the exposure (dither) number for a tile.\n",
    "\n",
    "So, now, we want to visualize all the exposures in the `F158` filter, and check the total exposure time. So we will take the `sim_table` Table and select all exposures with `BANDPASS == 'F158`. Then we will accumulate the exposure time. The exposures with `MA_TABLE_NUMBER == 5` have an exposure time of 295 seconds, whereas the exposures with `MA_TABLE_NUMBER == 6` have an exposure time of 107 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_mask = sim_table['BANDPASS'] == 'F158'\n",
    "sub_table = sim_table[table_mask]\n",
    "exp_time = np.ones(np.count_nonzero(table_mask))\n",
    "exp_time[sub_table['MA_TABLE_NUMBER'] == 6] = 295\n",
    "exp_time[sub_table['MA_TABLE_NUMBER'] == 5] = 107\n",
    "ra_sim = sub_table['RA'].data\n",
    "dec_sim = sub_table['DEC'].data\n",
    "pa_sim = sub_table['PA'].data\n",
    "\n",
    "print('Number of selected exposures', len(sub_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, instead of a reference position and the relative `V2`, `V3` angles, we directly have the `RA`, `DEC`, and `PA` of the `WFI_CEN` aperture so we can used these directly via `build_single_exp_map_cen`. Let's start with a single segment within the HLWAS medium field (Survey Step 97)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_here = (sub_table['PASS'] == 97) & (sub_table['SEGMENT'] == 1)\n",
    "print('Going to use', np.count_nonzero(mask_here), 'exposures')\n",
    "map_result = None\n",
    "for ra, dec, pa, et in zip(ra_sim[mask_here], dec_sim[mask_here], pa_sim[mask_here], exp_time[mask_here]):\n",
    "    map_here = build_single_exp_map_cen(ra, dec, pa, et, nside_cov=nside_cov, nside_sparse=nside_sparse)\n",
    "    if map_result is None:\n",
    "        map_result = map_here\n",
    "    else:\n",
    "        map_result = hsp.sum_union([map_result, map_here])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(4, figsize=(8, 6))\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "sp = skyproj.McBrydeSkyproj(ax=ax)\n",
    "\n",
    "# We define here a custom colorbar for illustration purposes\n",
    "cmap = plt.cm.Blues  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0, 400, 100)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "# Note that the default is to zoom in to the range defined by the map\n",
    "_ = sp.draw_hspmap(map_result, cmap=cmap, norm=norm)\n",
    "# Set up the colorbar\n",
    "cbar, _ = sp.draw_inset_colorbar(label='Total exposure time (s)', height='3%', bbox_to_anchor=(-0.06, -0.1, 1, 1), loc=1, ticks=[107, 214, 321])\n",
    "cbar.ax.set_xticklabels(['107', '214', '321'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do all of the exposures using the F158 filter element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 15\n",
    "ra_sim = sub_table['RA'].data\n",
    "dec_sim = sub_table['DEC'].data\n",
    "pa_sim = sub_table['PA'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-open the dask client\n",
    "client = Client(processes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_all = []\n",
    "for i in range(niter):\n",
    "    print('Iteration', i)\n",
    "    imin = (i*len(ra_sim))//niter\n",
    "    imax = ((i+1)*len(ra_sim))//niter\n",
    "    ra_subset = ra_sim[imin:imax]\n",
    "    dec_subset = dec_sim[imin:imax]\n",
    "    pa_subset = pa_sim[imin:imax]\n",
    "    exp_subset = exp_time[imin:imax]\n",
    "    map_here = client.map(partial(build_single_exp_map_cen, nside_sparse=nside_sparse, nside_cov=nside_cov),\n",
    "                          ra_subset, dec_subset, pa_subset, exp_subset)\n",
    "    map_partial = client.map(hsp.sum_union, [map_here])\n",
    "    res_here = map_partial[0].result()\n",
    "    map_all.append(res_here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_f158 = hsp.sum_union(map_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(5, figsize=(10, 6))\n",
    "fig.clf()\n",
    "ax = fig.add_subplot(111)\n",
    "sp = skyproj.McBrydeSkyproj(ax=ax)\n",
    "\n",
    "# We define here a custom colorbar for illustration purposes\n",
    "cmap = plt.cm.Blues  # define the colormap\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "# create the new map\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "    'Custom cmap', cmaplist, cmap.N)\n",
    "bounds = np.linspace(0, 3000, 200)\n",
    "norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "# Note that the default is to zoom in to the range defined by the map\n",
    "_ = sp.draw_hspmap(map_f158, cmap=cmap, norm=norm)\n",
    "# Set up the colorbar\n",
    "cbar, _ = sp.draw_inset_colorbar(label='Total exposure time (s)', height='100%', width='1%', orientation='vertical',\n",
    "                                 bbox_to_anchor=(+0.06, -0.1, 1, 1), loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting `healsparse` maps can be saved to disk using the `write` method.\n",
    "\n",
    "Disclaimer: Depending on the map resolution (controlled by the `nside` parameter) it can generate a very large file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_f158.write('./data/map_f158_all.hsp')  # Uncomment if you want to write the map to disk. With the default parameters in this notebook it should use 45 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this Notebook\n",
    "\n",
    "**Author(s):** Javier SÃ¡nchez <br>\n",
    "**Keyword(s):** Tutorial, visualization, survey footprints <br>\n",
    "**Last Updated:** Oct 2025 <br>\n",
    "**Next Review:** \n",
    "***\n",
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
